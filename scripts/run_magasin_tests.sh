#!/bin/bash

# Script d'ex√©cution des tests d'int√©gration pour le module magasin
# LOG430 - Labo5 Microservices

set -e  # Arr√™ter en cas d'erreur

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
TESTS_DIR="$PROJECT_ROOT/tests/integration"

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fonctions utilitaires
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# V√©rification de l'environnement
check_environment() {
    log_info "üîç V√©rification de l'environnement..."
    
    # Forcer l'utilisation de SQLite pour les tests (√©vite les probl√®mes de connexion PostgreSQL)
    export DATABASE_URL="sqlite:///test_db.sqlite3"
    log_info "Configuration base de donn√©es: SQLite ($DATABASE_URL)"
    
    # V√©rifier que pytest est install√©
    if ! command -v pytest &> /dev/null; then
        log_error "pytest n'est pas install√©. Installation..."
        pip install pytest pytest-django pytest-cov
    fi
    
    # V√©rifier les d√©pendances pour les tests
    log_info "Installation des d√©pendances de test..."
    if [ -f "$PROJECT_ROOT/requirements-test.txt" ]; then
        pip install -r "$PROJECT_ROOT/requirements-test.txt"
    else
        # Fallback si requirements-test.txt n'existe pas
        pip install responses factory-boy freezegun pytest-mock pytest-xdist pytest-env
    fi
    
    # V√©rifier la configuration Django
    if [ ! -f "$PROJECT_ROOT/pytest.ini" ]; then
        log_error "pytest.ini manquant"
        exit 1
    fi
    
    log_success "Environnement pr√™t"
}

# Fonction pour attendre que les services soient pr√™ts
wait_for_services() {
    log_info "‚è≥ Attente des services..."
    
    local max_attempts=30
    local attempt=0
    
    # Attendre Django
    while ! curl -s http://localhost:80 > /dev/null 2>&1; do
        attempt=$((attempt + 1))
        if [ $attempt -gt $max_attempts ]; then
            log_warning "Django app non disponible - tests E2E limit√©s"
            break
        fi
        sleep 2
    done
    
    # Attendre Kong (optionnel pour tests E2E)
    if curl -s http://localhost:8080 > /dev/null 2>&1; then
        log_success "Kong Gateway disponible"
        export KONG_AVAILABLE=true
    else
        log_warning "Kong Gateway non disponible - tests E2E sans Kong"
        export KONG_AVAILABLE=false
    fi
}

# D√©marrage des services n√©cessaires
start_services() {
    log_info "üöÄ D√©marrage des services..."
    
    cd "$PROJECT_ROOT"
    
    # D√©marrer les services essentiels pour les tests
    docker-compose up -d app redis
    
    # Attendre que les services soient pr√™ts
    wait_for_services
}

# Tests unitaires et d'int√©gration avec mocks
run_unit_integration_tests() {
    log_info "üß™ Ex√©cution des tests unitaires et d'int√©gration..."
    
    cd "$PROJECT_ROOT"
    
    # Tests des views avec mocks
    log_info "Tests des vues Django..."
    pytest -xvs tests/integration/test_magasin_views.py \
        --tb=short \
        --disable-warnings \
        -m "integration and not e2e"
    
    # Tests des clients HTTP avec mocks
    log_info "Tests des clients HTTP..."
    pytest -xvs tests/integration/test_magasin_clients.py \
        --tb=short \
        --disable-warnings \
        -m "integration and not e2e" || log_warning "Certains tests clients ont √©chou√© (normal si responses pas install√©)"
    
    # Tests de couverture et edge cases
    log_info "Tests de couverture..."
    pytest -xvs tests/integration/test_magasin_coverage.py \
        --tb=short \
        --disable-warnings \
        -m "integration and not e2e"
}

# Tests End-to-End avec vraies APIs
run_e2e_tests() {
    log_info "üåê Ex√©cution des tests End-to-End..."
    
    if [ "$KONG_AVAILABLE" = "true" ]; then
        log_info "Tests E2E complets avec Kong..."
        pytest -xvs tests/integration/test_magasin_e2e.py \
            --tb=short \
            --disable-warnings \
            -m "e2e"
    else
        log_info "Tests E2E limit√©s (sans Kong)..."
        pytest -xvs tests/integration/test_magasin_e2e.py \
            --tb=short \
            --disable-warnings \
            -m "e2e and not integration" || true
    fi
}

# Tests de performance
run_performance_tests() {
    log_info "‚ö° Tests de performance..."
    
    pytest -xvs tests/integration/test_magasin_e2e.py::TestMagasinE2EPerformance \
        --tb=short \
        --disable-warnings || log_warning "Tests de performance √©chou√©s (normal si services lents)"
}

# Tests avec couverture de code
run_coverage_tests() {
    log_info "üìä Tests avec couverture de code..."
    
    cd "$PROJECT_ROOT"
    
    pytest tests/integration/ \
        --cov=magasin \
        --cov-report=html:coverage_reports/magasin \
        --cov-report=term-missing \
        --cov-config=.coveragerc \
        -m "integration and not e2e" \
        --disable-warnings || log_warning "Couverture partielle obtenue"
    
    if [ -d "coverage_reports/magasin" ]; then
        log_success "Rapport de couverture g√©n√©r√©: coverage_reports/magasin/index.html"
    fi
}

# Tests en parall√®le pour acc√©l√©rer
run_parallel_tests() {
    log_info "üî• Tests en parall√®le..."
    
    # Installer pytest-xdist si pas d√©j√† fait
    pip install pytest-xdist > /dev/null 2>&1 || true
    
    pytest tests/integration/ \
        -n auto \
        --tb=short \
        --disable-warnings \
        -m "integration and not e2e" || log_warning "Tests parall√®les partiellement r√©ussis"
}

# Nettoyage apr√®s tests
cleanup() {
    log_info "üßπ Nettoyage..."
    
    # Nettoyer les fichiers temporaires de test
    find "$PROJECT_ROOT" -name "*.pyc" -delete 2>/dev/null || true
    find "$PROJECT_ROOT" -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
    find "$PROJECT_ROOT" -name ".pytest_cache" -type d -exec rm -rf {} + 2>/dev/null || true
    
    # Optionnel: arr√™ter les services de test
    if [ "$STOP_SERVICES" = "true" ]; then
        cd "$PROJECT_ROOT"
        docker-compose stop app redis
    fi
    
    log_success "Nettoyage termin√©"
}

# Affichage du r√©sum√©
show_summary() {
    echo ""
    echo "=================================="
    echo "   R√âSUM√â DES TESTS MAGASIN"
    echo "=================================="
    echo ""
    echo "üìÅ Tests cr√©√©s:"
    echo "  ‚Ä¢ test_magasin_views.py      - Tests vues Django (mocks)"
    echo "  ‚Ä¢ test_magasin_clients.py    - Tests clients HTTP (mocks/real)"
    echo "  ‚Ä¢ test_magasin_e2e.py        - Tests End-to-End complets"
    echo "  ‚Ä¢ test_magasin_coverage.py   - Tests couverture & edge cases"
    echo ""
    echo "üéØ Types de tests couverts:"
    echo "  ‚úÖ Integration des views"
    echo "  ‚úÖ Integration des clients HTTP"
    echo "  ‚úÖ End-to-End workflows"
    echo "  ‚úÖ Gestion d'erreurs"
    echo "  ‚úÖ Performance de base"
    echo "  ‚úÖ Logging et observabilit√©"
    echo "  ‚úÖ Sessions Django"
    echo "  ‚úÖ Configuration et setup"
    echo ""
    echo "üìä Couverture attendue: 80%+"
    echo ""
    if [ -d "coverage_reports/magasin" ]; then
        echo "üìà Rapport d√©taill√©: coverage_reports/magasin/index.html"
    fi
    echo "=================================="
}

# Fonction principale
main() {
    echo ""
    echo "üß™ TESTS D'INT√âGRATION MAGASIN - LOG430 Labo5"
    echo "=============================================="
    echo ""
    
    # Parsing des arguments
    RUN_E2E=false
    RUN_COVERAGE=false
    RUN_PARALLEL=false
    STOP_SERVICES=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --e2e)
                RUN_E2E=true
                shift
                ;;
            --coverage)
                RUN_COVERAGE=true
                shift
                ;;
            --parallel)
                RUN_PARALLEL=true
                shift
                ;;
            --stop-services)
                STOP_SERVICES=true
                shift
                ;;
            --all)
                RUN_E2E=true
                RUN_COVERAGE=true
                shift
                ;;
            --help)
                echo "Usage: $0 [OPTIONS]"
                echo ""
                echo "Options:"
                echo "  --e2e              Inclure les tests End-to-End"
                echo "  --coverage         G√©n√©rer le rapport de couverture"
                echo "  --parallel         Ex√©cuter les tests en parall√®le"
                echo "  --stop-services    Arr√™ter les services apr√®s les tests"
                echo "  --all              Tous les tests (e2e + coverage)"
                echo "  --help             Afficher cette aide"
                echo ""
                exit 0
                ;;
            *)
                log_error "Option inconnue: $1"
                echo "Utilisez --help pour voir les options disponibles"
                exit 1
                ;;
        esac
    done
    
    # Pi√®ge pour nettoyage automatique
    trap cleanup EXIT
    
    # √âtapes d'ex√©cution
    check_environment
    start_services
    
    # Tests principaux
    if [ "$RUN_PARALLEL" = "true" ]; then
        run_parallel_tests
    else
        run_unit_integration_tests
    fi
    
    # Tests optionnels
    if [ "$RUN_E2E" = "true" ]; then
        run_e2e_tests
        run_performance_tests
    fi
    
    if [ "$RUN_COVERAGE" = "true" ]; then
        run_coverage_tests
    fi
    
    # R√©sum√© final
    show_summary
    
    log_success "üéâ Tests d'int√©gration magasin termin√©s!"
}

# Ex√©cution du script
main "$@" 